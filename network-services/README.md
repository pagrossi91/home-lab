# Network Services Stack - Complete Deployment Guide

This stack provides home network security, filtering, DNS management, and secure remote access services for homelab infrastructure. The configuration is designed to be as self-contained as possible through the docker compose file, with minimal external configuration required.

These services were set up with lots of google-foo. This README was generated by Claude and manually checked and revised against LLM-induced chaos.

## 🏗️ Architecture Overview

### Service Dependencies
```
Internet → Router → Pi-hole → DNSCrypt Proxy → Encrypted DNS Providers
                ↓
            Internal Network
                ↓
        SWAG (Reverse Proxy) → Internal Services
```

### Network Design Philosophy
- **Single Custom Bridge Network**: All services use `nginx_network` for inter-service communication
- **Static IP Assignment**: Prevents configuration drift across container restarts
- **Encrypted DNS Chain**: All DNS queries are encrypted before leaving the network
- **Secure External Access**: Only HTTPS traffic allowed through SWAG reverse proxy

## 🚀 Initial Setup

### Prerequisites
1. Docker and Docker Compose installed
2. Port forwarding configured on router:
   - Port 80 → Docker host IP:80 (HTTP challenges)
   - Port 443 → Docker host IP:443 (HTTPS traffic)
3. DuckDNS account and subdomain created

### Directory Structure Setup

1. **Create project directory**:
   ```bash
   mkdir homelab-network-stack
   cd homelab-network-stack
   ```

2. **Create directory structure**:
   ```bash
   mkdir -p {pi-hole/{etc-pihole,etc-dnsmasq.d,var-log},dnscrypt/{proxy/config,server/{keys,unbound}},swag/config,portainer/data,duckdns/config}
   ```
   **Why**: These directories are all the mounted volumes listed for the services in the `docker-compose.yml` file. Failure to initialize these volumes manually will result in permission errors.

3. **Create log file**:
   ```bash
   touch ./pi-hole/var-log/pihole.log
   ```
   **Why**: Pi-hole container runs as user 999 and needs write permissions to the log file. If this file doesn't exist or has wrong permissions, Pi-hole will fail to start with error messages like "Permission denied: cannot create /var/log/pihole.log" or the container will exit with code 1.

4. **Set permissions**:
   ```bash
   sudo chown -R 1000:1000 ./pi-hole ./dnscrypt ./swag ./portainer ./duckdns
   ```
   **Why**: Containers run as user 1000 by default (specified by PUID in environment). Without proper ownership, you'll encounter:
   - Permission denied errors when containers try to write configuration files
   - Services failing to start with "Operation not permitted" errors
   - Configuration changes not persisting between container restarts
   - Log files not being written, making troubleshooting impossible

### Environment Configuration

Create `.env` file with your specific values. These keep sensitive variables like passwords out of your `docker-compose.yml` and in a separate file that `docker-compose.yml` can reference as a `${VARIABLE}`.

```bash
# User and timezone settings
LOCAL_USER=1000
TZ=America/New_York

# Pi-hole admin interface password
PIHOLE_WEBPASSWORD=your_secure_password_here

# Static IP Addresses on NGINX Docker Network
NGINX_NETWORK_SUBNET=172.XX.0.0/16
NGINX_NETWORK_GATEWAY=172.XX.0.1
PIHOLE_STATIC_IP=172.XX.0.10
DNSCRYPTSERVER_STATIC_IP=172.XX.0.11
DNSCRYPTPROXY_STATIC_IP=172.XX.0.12
SWAG_STATIC_IP=172.XX.0.99

# DuckDNS configuration
DUCKDNS=your_subdomain_here
DUCKDNS_TOKEN=your_duckdns_token_here
DOMAIN=${DUCKDNS}.duckdns.org

# SSL certificate email (for Let's Encrypt/ZeroSSL)
SSL_EMAIL=your_email@domain.com

# Watchtower email notifications
WATCHTOWER_NOTIFICATION_EMAIL_FROM=notifications@yourdomain.com
WATCHTOWER_NOTIFICATION_EMAIL_TO=admin@yourdomain.com
WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com
WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587
WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=your_smtp_user
WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=your_app_password
```

**Critical Environment Variables Explained**:
- `LOCAL_USER=1000`: Standard non-root user ID for containers. **Why**: If this doesn't match your host user ID, you'll get permission errors when containers try to access mounted volumes. Without this, configuration files won't be accessible and services will fail to start.
- `DUCKDNS`: Your DuckDNS subdomain (without .duckdns.org). **Why**: If this is incorrect, SSL certificate generation will fail because SWAG won't be able to complete DNS challenges, leaving you without HTTPS access.
- `DOMAIN=${DUCKDNS}.duckdns.org`: Full domain for SSL certificates. **Why**: This must exactly match your DuckDNS domain, or certificate requests will be rejected by the certificate authority.
- `SSL_EMAIL`: Required for ZeroSSL certificate provisioning. **Why**: Without this, certificate generation will fail with "Email address required" errors, and you'll fall back to Let's Encrypt with stricter rate limits.

## 📋 Service Configuration and Deployment

Deploy services in this specific order to ensure proper dependencies. After the initial deployment and you've confirmed all services are working properly, these can all be deployed in the single Docker stack (i.e., the entire `docker-compose.yml`) by running `docker compose up -d`.

### 1. DuckDNS Dynamic DNS

**Function**: Keeps external domain pointed to current public IP address

**Prerequisites**: 
- Manually create the volume directories in the docker-compose file. This should already have been completed in the Initial Setup section. 
- Create a DuckDNS account from [DuckDNS.org](https://www.duckdns.org) and retrieve the token.

#### Docker Compose Configuration
```yaml
duckdns:
  image: lscr.io/linuxserver/duckdns:latest
  container_name: duckdns
  networks:
    - nginx_network
  environment:
    PUID: ${LOCAL_USER}
    PGID: ${LOCAL_USER}
    TZ: ${TZ}
    SUBDOMAINS: ${DUCKDNS}
    TOKEN: ${DUCKDNS_TOKEN}
    LOG_FILE: "false"
  volumes:
    - ./duckdns/config:/config
```

**Key Parameters**:
- `SUBDOMAINS`: Your DuckDNS subdomain (without .duckdns.org)
- `TOKEN`: Authentication token from DuckDNS account
- `LOG_FILE: "false"`: Disables logging to reduce container size

#### Deployment
```bash
docker compose up -d duckdns
```
Wait 2-3 minutes for IP update.

**Why this order**: SWAG needs your domain to point to the correct IP address for SSL certificate validation. If DuckDNS hasn't updated your IP, certificate generation will fail with "DNS challenge failed" errors.

**Update Frequency**: Every 5 minutes (DuckDNS default)

**Why dynamic DNS is essential**:
- **Residential ISPs**: Most change IP addresses regularly (daily to weekly)
- **Certificate validation**: SSL certificates require domain to resolve to correct IP
- **External access**: Services become unreachable when IP changes
- **Without DuckDNS**: Manual IP updates required every time ISP changes your address

**Common issues and symptoms**:
- **Wrong token**: Updates fail silently, domain points to old IP
- **Network issues**: Domain stops updating, external access fails
- **Rate limiting**: Too frequent updates can trigger temporary blocks

#### Post-Deployment Configuration
No additional configuration required - service automatically updates IP every 5 minutes.

#### Troubleshooting
**Issue**: Domain not updating to current IP
```bash
# Test DuckDNS token manually
curl "https://www.duckdns.org/update?domains=${DUCKDNS}&token=${DUCKDNS_TOKEN}&ip="

# Check container logs
docker logs duckdns

# Verify current domain resolution
nslookup ${DUCKDNS}.duckdns.org
```

**Reference**: [DuckDNS Docker Documentation](https://docs.linuxserver.io/images/docker-duckdns/)

---

### 2. DNSCrypt Server (Optional)

**Function**: Self-hosted DNSCrypt server for homelab domain

> **Note**: Skip this service if you only plan to use [DNSCrypt servers from external organizations](https://dnscrypt.info/public-servers/). This provides a self-hosted, caching, non-censoring, non-logging, DNSSEC-capable, DNSCrypt-enabled DNS resolver.

**Prerequisites**: 
- Manually create the volume directories in the docker-compose file. This should already have been completed in the Initial Setup section. 

#### Docker Compose Configuration
```yaml
dnscrypt-server:
  image: jedisct1/dnscrypt-server:latest
  container_name: dnscrypt-server
  restart: always
  networks:
    nginx_network:
      ipv4_address: ${DNSCRYPTSERVER_STATIC_IP}
  command: "init -N ${DUCKDNS}.duckdns.org -E '${DNSCRYPTSERVER_STATIC_IP}:5443' -A"
  # command: "start"  # Use this for subsequent runs
  ports:
    - '5443:5443/udp'
    - '5443:5443/tcp'
  volumes:
    - ./dnscrypt/server/keys:/opt/encrypted-dns/etc/keys
    - ./dnscrypt/server/unbound:/opt/unbound/etc/unbound
  environment:
    TZ: ${TZ}
    PUID: ${LOCAL_USER}
    PGID: ${LOCAL_USER}
  depends_on:
    - pihole
```

**Key Parameters**:
- `command: "init"`: Generates cryptographic keys and configuration (first run only)
- `command: "start"`: Normal operation mode (subsequent runs)
- Static IP binding on port 5443 for DNSCrypt protocol

#### Deployment
1. **First-time initialization**:
   ```bash
   docker compose up dnscrypt-server
   ```
   Watch logs until you see "Provider information saved" then stop the container.

    **Why**: The `init` command generates the server's cryptographic keys and creates the encrypted-dns.toml configuration file. These are essential for the DNSCrypt server to function. Without initialization, the server will fail to start with errors like "No provider key found" or "Configuration file missing."

2. **Switch to start mode**:
   Edit docker-compose.yml to use `command: "start"` and comment out the `command: "init..."`, then:
   ```bash
   docker compose up -d dnscrypt-server
   ```

    **Why**: The `init` command should only be run once. If you try to run it again, it will fail with "Keys already exist" errors or overwrite your existing configuration, potentially breaking client connections. When you use the `start` command, DNSCrypt-server uses the configuration from your initial `init` run.

#### Post-Deployment Configuration
Verify key generation:
```bash
ls -la ./dnscrypt/server/keys/
```
   
   **What to expect**: You should see: `encrypted-dns.toml`, `provider_name`, and various `.key` files. If initialization fails, you'll see an empty keys directory and the container will exit immediately. The container logs will show "Failed to generate keys" or similar errors.

#### Troubleshooting
**Issue**: Initialization fails
```bash
# Check logs for errors
docker logs dnscrypt-server

# Verify permissions
sudo chown -R 1000:1000 ./dnscrypt/server/

# Clear and reinitialize
rm -rf ./dnscrypt/server/keys/*
# Switch back to init command and restart
```

**Reference**: [DNSCrypt Server Docker Documentation](https://github.com/dnscrypt/dnscrypt-server-docker)

---

### 3. DNSCrypt Proxy

**Function**: Encrypts and authenticates all DNS queries before sending to upstream servers

**Prerequisites**: 
- Manually create the volume directories in the docker-compose file. This should already have been completed in the Initial Setup section. 
- Create configuration file before deployment

#### Configuration File Setup
Create `./dnscrypt/proxy/config/dnscrypt-proxy.toml` or modify the example [DNSCrypt proxy toml file](https://github.com/DNSCrypt/dnscrypt-proxy/blob/master/dnscrypt-proxy/example-dnscrypt-proxy.toml):

```toml
# Logging and performance settings
listen_addresses = ['0.0.0.0:5053']
max_clients = 250
ipv4_servers = true
ipv6_servers = false
require_dnssec = false
require_nolog = true
require_nofilter = true
force_tcp = false
timeout = 5000
keepalive = 30
cert_refresh_delay = 240

# Caching configuration
cache = true
cache_size = 4096
cache_min_ttl = 2400
cache_max_ttl = 86400

# Server selection - Mix of DNSCrypt and DoH servers
server_names = [
    # DNSCrypt servers
    'cs-nyc',
    'scaleway-fr', 
    'cs-ch',
    'dnscry.pt-amsterdam-ipv4',
    # DoH servers
    'adguard-dns-doh',
    'mullvad-base-doh',
    'nextdns'
]

# Anonymous DNS relay configuration for enhanced privacy
routes = [
    { server_name='cs-nyc', via=['dnscry.pt-anon-philadelphia-ipv4'] },
    { server_name='scaleway-fr', via=['anon-cs-nyc'] },
    { server_name='cs-ch', via=['dnscry.pt-anon-chicago-ipv4'] },
    { server_name='dnscry.pt-amsterdam-ipv4', via=['anon-cs-ga'] }
]
```

---
#### Key Configuration Explained

```toml
require_nolog = true
require_nofilter = true
```
**Why essential for privacy**: 
- **require_nolog**: Eliminates servers that log DNS queries, preventing tracking
- **require_nofilter**: Prevents DNS-level filtering (Pi-hole handles filtering locally)
- **Without these**: Your DNS queries could be logged, sold, or used for tracking

```toml
cache_size = 4096
cache_min_ttl = 2400
cache_max_ttl = 86400
```
**Why caching matters**: 
- Reduces upstream queries by 60-80% in typical usage
- Improves response times from ~100ms to ~1ms for cached queries
- Reduces bandwidth and improves privacy (fewer external requests)
- **Without caching**: Every DNS query goes upstream, increasing latency and exposure

```toml
timeout = 5000
keepalive = 30
```
**Why timeout/keepalive tuning**:
- **5000ms timeout**: Accommodates slower relay chains without failing
- **30s keepalive**: Maintains connections to reduce connection overhead
- **Too low**: Queries fail with timeout errors
- **Too high**: Resource waste and slower failover

---
#### Server Selection Strategy

**DNSCrypt Servers Selected**:
- `cs-nyc`: CryptoStorm New York - US East Coast
- `scaleway-fr`: Scaleway France - European coverage
- `cs-ch`: CryptoStorm Switzerland - European privacy-focused
- `dnscry.pt-amsterdam-ipv4`: Netherlands-based server

**DoH Servers Selected**:
- `adguard-dns-doh`: AdGuard DNS-over-HTTPS
- `mullvad-base-doh`: Mullvad VPN's DNS service
- `nextdns`: NextDNS service

**Why this mix**: 
- **Geographic diversity**: Servers across different continents reduce latency and provide failover options
- **Provider diversity**: Different organizations prevent single points of failure
- **Protocol diversity**: Mix of DNSCrypt and DoH provides redundancy if one protocol has issues
- **Privacy focus**: Selected providers have strong privacy policies and no-logging commitments

---
#### Anonymous DNS Relay Configuration

**Why relays are important**: The relay routes add an extra layer of privacy by routing DNS queries through intermediate relays before reaching the final DNS server. This prevents the DNS server from knowing your real IP address, similar to how Tor works.

**Relay Strategy**:
- **Geographic separation**: Relays are in different locations from their target servers
- **Provider separation**: Relays use different providers than target servers where possible
- **Latency consideration**: Relay paths are optimized to minimize additional latency

**What happens without relays**: Your real IP address is visible to the DNS servers, potentially allowing correlation of DNS queries with your identity.

**Performance Impact**:
- **Additional latency**: 20-50ms per query (usually acceptable)
- **Redundancy**: If relay fails, direct connection is attempted
- **Load balancing**: Distributes traffic across multiple relays

**What happens without relays**: DNS servers can potentially:
- Log your IP address with query history
- Build profiles of your browsing habits
- Correlate queries with other data sources
- Comply with government data requests including your query history

#### Docker Compose Configuration
```yaml
dnscrypt-proxy:
  container_name: dnscrypt-proxy
  image: klutchell/dnscrypt-proxy:latest
  user: "${LOCAL_USER}:${LOCAL_USER}"
  ports:
    - "5053:5053/tcp"
    - "5053:5053/udp"
  networks:
    nginx_network:
      ipv4_address: ${DNSCRYPTPROXY_STATIC_IP}
  environment:
    PUID: ${LOCAL_USER}
    PGID: ${LOCAL_USER}
  volumes:
    - ./dnscrypt/proxy/config:/config
  restart: unless-stopped
```

#### Deployment
```bash
docker compose up -d dnscrypt-proxy
```

#### Post-Deployment Configuration
Verify servers are responding:
```bash
# Check server connectivity and latency
docker logs dnscrypt-proxy 2>&1 | grep -E "(latency|ready|server)" | tail -10
```

Expected output showing live servers and latency measurements.

---
#### Troubleshooting
**Issue**: No servers available
```bash
# Check configuration syntax
docker exec dnscrypt-proxy cat /config/dnscrypt-proxy.toml

# Test direct connection
dig @${DNSCRYPTPROXY_STATIC_IP} -p 5053 google.com

# Check logs for server failures
docker logs dnscrypt-proxy | grep -i error
```

**Reference**: [DNSCrypt Proxy Documentation](https://github.com/DNSCrypt/dnscrypt-proxy/wiki)

---

### 4. Pi-hole DNS Filter

**Function**: Network-wide DNS filtering and ad blocking

**Prerequisites**: 
- DNSCrypt Proxy must be running first
- Manually create the volume directories in the docker-compose file. This should already have been completed in the Initial Setup section.
- Manually create the `pihole.log` file from the docker-compose file. This should already have been completed in the Initial Setup section. 

#### Docker Compose Configuration
```yaml
pihole:
  container_name: pihole
  image: pihole/pihole:latest
  hostname: pihole-docker
  networks:
    nginx_network:
      ipv4_address: ${PIHOLE_STATIC_IP}
  ports:
    - "53:53/tcp"
    - "53:53/udp"
    - "81:80/tcp"
    - "444:443/tcp"
  environment:
    FTLCONF_webserver_api_password: ${PIHOLE_WEBPASSWORD}
    FTLCONF_dns_upstreams: ${DNSCRYPTPROXY_STATIC_IP}#5053
    FTLCONF_dns_listeningMode: all
    TZ: ${TZ}
  volumes:
    - './pi-hole/etc-pihole/:/etc/pihole/'
    - './pi-hole/etc-dnsmasq.d/:/etc/dnsmasq.d/'
    - './pi-hole/var-log/pihole.log:/var/log/pihole.log'
  cap_add:
    - NET_ADMIN
    - SYS_TIME 
    - SYS_NICE
  labels:
    - "com.centurylinklabs.watchtower.enable=false"
  depends_on:
    - dnscrypt-proxy
```

**Critical Docker Compose Settings Explained**:

```yaml
FTLCONF_dns_listeningMode: all
```
**Why critical**: Default "single" mode only binds to the default Docker bridge interface. With custom networks, Pi-hole won't receive DNS requests from other containers or network clients, causing complete DNS failure with "Connection refused" errors. The container will appear healthy but DNS resolution will fail silently.

```yaml
FTLCONF_dns_upstreams: 172.18.0.12#5053
```
**Why specific IP and port**: 
- **IP**: Static IP ensures the setting persists across container restarts
- **Port 5053**: DNSCrypt proxy listens on this non-standard port to avoid conflicts
- **Without this**: Pi-hole would use default DNS servers (1.1.1.1, 8.8.8.8), bypassing encryption and privacy protections

```yaml
ports:
  - "81:80/tcp"    # Web interface on port 81 (avoids conflicts)
  - "444:443/tcp"  # HTTPS interface on port 444
```
**Why non-standard ports**: Port 80/443 are reserved for SWAG reverse proxy. Using standard ports would cause:
- Port conflicts preventing Pi-hole from starting
- SWAG unable to bind to ports, breaking external access
- "Address already in use" errors in container logs

```yaml
cap_add:
  - NET_ADMIN
```
**Why needed**: Required for DHCP functionality (even if not used) and certain network operations. Without it:
- Container startup may fail with "Operation not permitted"
- Network configuration changes inside container will fail
- Some Pi-hole features may not work correctly

---
#### Deployment
```bash
docker compose up -d pihole
```

#### Post-Deployment Configuration

1. **Access Pi-hole admin**: `http://your-server-ip:81/admin`
2. **Login** with `PIHOLE_WEBPASSWORD` from .env file
3. **Verify upstream DNS**:
   - Settings → DNS → Upstream DNS Servers
   - Confirm only custom server `${DNSCRYPTPROXY_STATIC_IP}#5053` is checked
4. **Configure listening interface**:
   - Settings → DNS → Interface listening behavior
   - Select "Listen on all interfaces"
5. **Verify DNS and blocking functionality**: Conduct the troubleshooting steps below to verify DNS resolution,  routing to DNSCrypt, and ad blocking are working. If they are, proceed to the next step. Else, search logs relevant to the troubleshooting step that failed.
6. **Router DNS Configuration**
    - Primary DNS: Set to your Docker host IP
      > **Note**: This should be `192.168.XX.XXX` and not the internal docker IP address set in the `.env` file, which would look like `172.XX.0.10`.
    - Secondary DNS: Set to 1.1.1.1 or 8.8.8.8 (backup)
    - DHCP settings: Ensure router continues handling DHCP
  
    **Why router configuration is essential**: Without pointing your router to Pi-hole:
    - Network-wide ad blocking won't function
    - Clients will use ISP DNS servers (usually plain text)
    - You'll lose centralized DNS filtering and logging
    - The entire DNS privacy chain is bypassed

    **What happens if misconfigured**: Devices will use default DNS servers, experiencing slower resolution, no ad blocking, and potential DNS manipulation by ISPs or man-in-the-middle attacks.

  7. **Enhanced Blocklists** (optional):
  The default Gravity lists (i.e. the list of domains to block) are generally sufficient. However, add the following lists from [Hagezi](https://github.com/hagezi/dns-blocklists) for more thorough filtering. These can be added from the Pi-Hole Web Portal in the Lists section:

      - *Hagezi multi pro*: `https://raw.githubusercontent.com/hagezi/dns-blocklists/main/hosts/pro.txt`
      - *Hagezi threat intelligence feed*: `https://raw.githubusercontent.com/hagezi/dns-blocklists/main/hosts/tif.txt`
      - *Smart TV blocklist*: `https://blocklistproject.github.io/Lists/smart-tv.txt`
      - *TikTok blocklist*: `https://blocklistproject.github.io/Lists/tiktok.txt`
      - *Ads blocklist*: `https://blocklistproject.github.io/Lists/ads.txt`
      - *Tracker blocklist*: `https://blocklistproject.github.io/Lists/tracking.txt`

#### Troubleshooting

These steps will help you identify the problem. Resolutions will likely be more specific and require some google-foo. Claude or ChatGPT can also be surprisingly helpful decifering logs for errors.

**Issue**: DNS resolution not working
```bash
# Test Pi-hole directly
dig @${PIHOLE_STATIC_IP} google.com

# Check if Pi-hole can reach DNSCrypt proxy
dig @${PIHOLE_STATIC_IP} -p 5053 google.com

# Verify container networking
docker exec pihole nslookup google.com ${DNSCRYPTPROXY_STATIC_IP}
```

**Issue**: Ad blocking not working
```bash
# Test known ad domain
dig @${PIHOLE_STATIC_IP} doubleclick.net

# Should return 0.0.0.0 if blocking works
```

**Reference**: [Pi-hole Docker Documentation](https://github.com/pi-hole/docker-pi-hole#readme)

---

### 5. SWAG Reverse Proxy

**Function**: Secure external access with automatic SSL certificate management

**Prerequisites**: 
- DuckDNS must be updating correctly
- Manually create the volume directories in the docker-compose file. This should already have been completed in the Initial Setup section.

#### Docker Compose Configuration
```yaml
swag:
  image: lscr.io/linuxserver/swag:latest
  container_name: swag
  networks:
    nginx_network:
      ipv4_address: ${SWAG_STATIC_IP}
  cap_add:
    - NET_ADMIN
  environment:
    PUID: ${LOCAL_USER}
    PGID: ${LOCAL_USER}
    TZ: ${TZ}
    URL: ${DOMAIN}
    VALIDATION: dns
    SUBDOMAINS: wildcard
    CERTPROVIDER: zerossl
    DNSPLUGIN: duckdns
    EMAIL: ${SSL_EMAIL}
    ONLY_SUBDOMAINS: false
    STAGING: false
  volumes:
    - ./swag/config:/config
  ports:
    - 443:443
    - 80:80
```

**Critical Environment Variables**:

```yaml
VALIDATION: dns
DNSPLUGIN: duckdns
SUBDOMAINS: wildcard
```
**Why DNS validation with DuckDNS**:
- **No port 80 exposure required**: HTTP challenge would require exposing internal services
- **Wildcard certificates**: Single cert covers all subdomains (*.yourdomain.duckdns.org)
- **Automated renewal**: DuckDNS plugin handles DNS challenges automatically
- **Without this**: Manual certificate management or security risks from HTTP challenges

```yaml
CERTPROVIDER: zerossl
```
**Why ZeroSSL over Let's Encrypt**:
- **Higher rate limits**: 300 certificates per domain per day vs 50 for Let's Encrypt
- **Better for testing**: Less likely to hit limits during configuration
- **Automatic fallback**: Falls back to Let's Encrypt if ZeroSSL fails
- **Same security**: Both provide Domain Validated certificates

#### Deployment
```bash
docker compose up -d swag
```

#### Post-Deployment Configuration

1. **Verify certificate generation**:
   ```bash
   docker logs swag
   ```
   Look for "Server ready" message.

   **What errors to watch for**:
   - "DNS challenge failed": DuckDNS token incorrect or domain not updated
   - "Rate limit exceeded": Too many certificate requests; wait 1 hour or switch to staging
   - "Email required": SSL_EMAIL environment variable missing

2. **Check certificate files**:
   ```bash
   ls -la ./swag/config/etc/letsencrypt/live/${DUCKDNS}.duckdns.org/
   ```
   Should contain: `cert.pem`, `chain.pem`, `fullchain.pem`, `privkey.pem`

   **Why this check matters**: Without these files, HTTPS connections will fail with "SSL certificate not found" errors, forcing all traffic over unencrypted HTTP.

3. **Proxy Configuration Files**: `./swag/config/nginx/proxy-confs/`

    Each service needing external access requires a proxy configuration file. Sample configurations are provided by default with the SWAG container. Duplicate the file of the service requiring external access and remove the `.sample` suffix.

    Once configured, the service will be available at `https://<server_name>.<subdomain>.duckdns.org` (e.g. `https://pihole.<subdomain>.duckdns.org`).

    **Example**: `./swag/config/nginx/proxy-confs/pihole.subdomain.conf`
    ```nginx
    server {
        listen 443 ssl http2;
        server_name pihole.*;

        include /config/nginx/ssl.conf;

        location / {
            include /config/nginx/proxy.conf;
            resolver 127.0.0.11 valid=30s;
            set $upstream_app pihole;
            set $upstream_port 80;
            set $upstream_proto http;
            proxy_pass $upstream_proto://$upstream_app:$upstream_port;
        }
    }
    ```

    **Why container name resolution**:
    - **Flexibility**: Match the `$upstream_app` variable to the container name. Container IP addresses can change (unless you prescribe the container IP in `docker-compose.yml`); names are consistent. 
      > This doesn't always work with the container name for some undetermined reason, so prescribed container IP addresses can be an effective fallback option. This IP would be the Docker network IP address (e.g., `172.XX.0.XX`).
    - **Docker DNS**: Docker provides automatic name resolution within networks
    - **Maintenance**: No need to update proxy configs when IPs change
    - **Without this**: Hardcoded IPs break when containers restart with different addresses (unless you prescribe the container IP in `docker-compose.yml`)

#### Troubleshooting
**Issue**: Certificate generation fails
```bash
# Check specific error
docker logs swag | grep -i error

# Test DuckDNS token
curl "https://www.duckdns.org/update?domains=${DUCKDNS}&token=${DUCKDNS_TOKEN}&ip="

# Verify domain resolution
nslookup ${DUCKDNS}.duckdns.org
```

**Issue**: External access not working
```bash
# Test internal SWAG access
curl -k https://${SWAG_STATIC_IP}

# Check port forwarding
nmap -p 80,443 your-external-ip
```

**Reference**: [SWAG Documentation](https://docs.linuxserver.io/general/swag)

---

### 6. Portainer Container Management

**Function**: Web-based Docker management interface

**Prerequisites**: 
- Manually create the volume directories in the docker-compose file. This should already have been completed in the Initial Setup section.

#### Docker Compose Configuration
```yaml
portainer:
  image: portainer/portainer-ce:latest
  container_name: portainer
  networks:
    - nginx_network
  command: -H unix:///var/run/docker.sock
  environment:
    TZ: ${TZ}
  ports:
    - 9000:9000
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock
    - ./portainer/data:/data
```

#### Deployment
```bash
docker compose up -d portainer
```

**Why Portainer is valuable**:
- **Visual management**: See container status, logs, and statistics at a glance
- **Troubleshooting**: Easy access to container logs and shell access
- **Resource monitoring**: CPU, memory, and network usage tracking
- **Stack management**: Deploy and update entire compose stacks through UI

**Security considerations**:
- **Docker socket access**: Has full control over Docker daemon
- **Network exposure**: Only accessible on local network by default
- **Admin password**: Use strong password; note there is no password recovery mechanism

#### Post-Deployment Configuration
1. Access `http://your-server-ip:9000`
2. Create admin user on first access
3. Connect to local Docker socket (automatic)

#### Troubleshooting
**Issue**: Cannot connect to Docker
```bash
# Verify Docker socket permissions
ls -la /var/run/docker.sock

# Check if user is in docker group
groups $USER
```

---

### 7. Watchtower Automatic Updates

**Function**: Automatic container image updates

**Prerequisites**: Email configuration for notifications

#### Docker Compose Configuration
```yaml
watchtower:
  container_name: watchtower
  image: containrrr/watchtower:latest
  hostname: watchtower-docker
  networks:
    - nginx_network
  environment:
    TZ: ${TZ}
    WATCHTOWER_CLEANUP: 'true'
    WATCHTOWER_NOTIFICATIONS: 'email'
    WATCHTOWER_NOTIFICATION_EMAIL_FROM: ${WATCHTOWER_NOTIFICATION_EMAIL_FROM}
    WATCHTOWER_NOTIFICATION_EMAIL_TO: ${WATCHTOWER_NOTIFICATION_EMAIL_TO}
    WATCHTOWER_NOTIFICATION_EMAIL_SERVER: ${WATCHTOWER_NOTIFICATION_EMAIL_SERVER}
    WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT: ${WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT}
    WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER: ${WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER}
    WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD: ${WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD}
  volumes:
    - '/var/run/docker.sock:/var/run/docker.sock'
    - '../../.docker/config.json:/config.json'
  command: --schedule '0 0 3 * * *'
```

**Key Parameters**:
- `WATCHTOWER_CLEANUP: 'true'`: Removes old images after update
- `command: --schedule '0 0 3 * * *'`: Updates daily at 3:00 AM
- Containers can excluded via labels to prevent automatic updates with
  ```yaml
  labels:
    - "com.centurylinklabs.watchtower.enable=false"
  ```

**Why automatic updates matter**:
- **Security patches**: Containers get security fixes without manual intervention
- **Feature updates**: Latest features and bug fixes automatically applied
- **Maintenance reduction**: Eliminates need for manual update checking

**Why Pi-hole (and certain other containers) should be excluded**:
- **Breaking changes**: Updates can change configuration formats
- **Custom settings**: Updates might reset custom configurations
- **Disruptions of critical services**: Failed Pi-hole updates break DNS for entire network. If you use Watchtower, recommend reserving it for non-critical services.
- **Manual testing preferred**: DNS is too critical for automatic updates
- **Difficulty tracking changes**: Automatic updates can make it difficult to track when the breaking change occurred.

**Email notification benefits**:
- **Update awareness**: Know when containers are updated
- **Failure alerts**: Get notified if updates fail
- **Change tracking**: Maintain awareness of what changed when

**What happens without notifications**:
- **Silent failures**: Update failures go unnoticed
- **Security lag**: Don't know if security updates are applied
- **Troubleshooting difficulty**: Hard to correlate issues with recent updates

#### Deployment
```bash
docker compose up -d watchtower
```

#### Post-Deployment Configuration
No additional configuration required. Monitor email notifications for update reports.

#### Troubleshooting
**Issue**: Email notifications not working
```bash
# Test email settings
docker logs watchtower

# Verify SMTP credentials in .env file
```

## 🌐 Network Configuration Deep Dive

### Custom Bridge Network: nginx_network

**Subnet**: `172.XX.0.0/16`  
**Gateway**: `172.XX.0.1`

**Why Custom Network is Essential**:
- **Container Communication**: Enables automatic DNS resolution between containers
- **Static IP Assignment**: Allows predictable service addressing
- **Security Isolation**: Isolates services from other Docker containers
- **Performance**: Direct container communication without NAT

### Static IP Address Strategy

**IP Assignments**:
- **Pi-hole (`172.XX.0.10`)**: Central DNS role, easy to remember
- **DNSCrypt Server (`172.XX.0.11`)**: Sequential numbering
- **DNSCrypt Proxy (`172.XX.0.12`)**: Upstream relationship to Pi-hole
- **SWAG (`172.XX.0.99`)**: High number for "gateway" function

**Benefits**:
- Configuration persistence across container restarts
- Reliable service dependencies
- Simplified troubleshooting and documentation

### DNS Resolution Flow

```
Client Request
     ↓
Router (configured to use Pi-hole)
     ↓
Pi-hole (172.XX.0.10:53) - Ad/malware filtering + caching
     ↓
DNSCrypt Proxy (172.XX.0.12:5053) - Query encryption
     ↓
Anonymous Relay (geographic anonymization)
     ↓
DNS Server (encrypted DNSCrypt/DoH connection)
     ↓
Response (encrypted back through chain)
     ↓
Pi-hole (final filtering and caching)
     ↓
Client (clean, fast response)
```

**Security Benefits**:
1. **Query Encryption**: All upstream DNS queries encrypted
2. **IP Anonymization**: Relays hide real IP from DNS servers
3. **Content Filtering**: Malicious domains blocked before reaching devices
4. **Geographic Diversity**: Multiple server locations prevent single points of failure
5. **Provider Diversity**: Multiple DNS providers prevent vendor lock-in

**Performance Characteristics**:
- **Cached queries**: 1-5ms response time
- **New queries**: 50-150ms including relay overhead
- **Cache hit rate**: Typically 60-80% for residential usage

## 🔍 DNS Security Verification

### Complete Security Audit Script

Run this comprehensive test to verify all security components:

```bash
#!/bin/bash
# Load environment variables and get Pi-hole IP
source .env 2>/dev/null || echo "Warning: .env file not found, using default IPs"
PIHOLE_IP=${PIHOLE_STATIC_IP:-$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' pihole 2>/dev/null || echo "172.18.0.10")}

echo "=== DNS Security Audit (Pi-hole: $PIHOLE_IP) ==="

echo "1. Checking for DNS leaks..."
timeout 10 sudo tcpdump -i $(ip route | grep default | awk '{print $5}') port 53 | grep -v "lpgrossi18.duckdns.org" && echo "❌ DNS LEAK DETECTED!" || echo "✅ No DNS leaks found"

echo "2. Testing Pi-hole blocking..."
dig @$PIHOLE_IP doubleclick.net | grep "0.0.0.0" > /dev/null && echo "✅ Pi-hole blocking works" || echo "❌ Pi-hole blocking failed"

echo "3. Checking DNSCrypt servers..."
docker logs dnscrypt-proxy 2>&1 | grep "live servers" | tail -1

echo "4. Testing DNS resolution..."
dig @$PIHOLE_IP google.com > /dev/null && echo "✅ DNS resolution works" || echo "❌ DNS resolution failed"

echo "5. Checking container health..."
docker compose ps | grep -E "(Up|healthy)" > /dev/null && echo "✅ Containers healthy" || echo "❌ Container issues detected"
```

The output should be similar to the following:

```bash
=== DNS Security Audit (Pi-hole: 172.XX.0.10) ===
1. Checking for DNS leaks...
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on enp3s0, link-type EN10MB (Ethernet), snapshot length 262144 bytes
tcpdump: Unable to write output: Broken pipe
Terminated
✅ No DNS leaks found
2. Testing Pi-hole blocking...
✅ Pi-hole blocking works
3. Checking DNSCrypt servers...
[2025-08-21 04:00:20] [NOTICE] dnscrypt-proxy is ready - live servers: 7
4. Testing DNS resolution...
✅ DNS resolution works
5. Checking container health...
✅ Containers healthy
```
### Individual Component Tests

**DNS Leak Detection**:
```bash
# Monitor for unauthorized DNS traffic
sudo tcpdump -i $(ip route | grep default | awk '{print $5}') port 53 -v
```
Should only show traffic to/from your Pi-hole container.

**Ad Blocking Verification**:
```bash
# Test known ad domains
dig @$PIHOLE_IP doubleclick.net
dig @$PIHOLE_IP googleadservices.com
```
Should return `0.0.0.0` for blocked domains.

**Encryption Verification**:
```bash
# Check DNSCrypt proxy status
docker logs dnscrypt-proxy 2>&1 | grep -E "(latency|ready|server)"
```
Should show multiple live servers with latency measurements.

**Relay Chain Verification**:
```bash
# Check for relay usage
docker logs dnscrypt-proxy 2>&1 | grep -i relay
```
Should show `[NOTICE] Source [relays] loaded`.

## 🎯 System Capabilities Summary

With all services properly configured and verified, your network stack provides:

### 🔒 **Security Features**
- **Encrypted DNS**: All queries encrypted via DNSCrypt and DoH protocols
- **Anonymous Resolution**: IP address hidden from DNS servers via relay chains
- **Content Filtering**: Network-wide blocking of ads, malware, and tracking domains
- **Secure External Access**: HTTPS-only access to internal services via reverse proxy
- **Automatic SSL**: Certificate generation and renewal with wildcard support

### 🚀 **Performance Benefits**
- **DNS Caching**: 60-80% cache hit rate reduces external queries
- **Geographic Diversity**: Multiple server locations ensure availability
- **Load Balancing**: Automatic failover between DNS servers
- **Optimized Routing**: Direct container communication reduces latency

### 🛡️ **Privacy Protection**
- **Query Anonymization**: Real IP address hidden from DNS providers
- **No DNS Logging**: Selected servers don't log or sell query data
- **Traffic Analysis Resistance**: Relay routing prevents correlation attacks
- **ISP Bypass**: Encrypted queries prevent ISP DNS manipulation

### 📊 **Management Capabilities**
- **Centralized Monitoring**: Portainer provides container oversight
- **Automatic Updates**: Watchtower keeps non-critical services current
- **Comprehensive Logging**: Detailed logs for troubleshooting and analysis
- **Dynamic DNS**: Automatic external IP updates for reliable access

### 🔧 **Operational Excellence**
- **Container Orchestration**: Docker Compose for consistent deployments
- **Configuration Management**: Environment variables for easy customization
- **Health Monitoring**: Built-in health checks and status reporting
- **Backup-Ready**: All critical configurations in persistent volumes

This stack transforms a basic home network into an enterprise-grade, privacy-focused DNS infrastructure with secure remote access capabilities.